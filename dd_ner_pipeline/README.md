# GLINERDD  - Named Entity Recognition Disque Den√∫ncia - GLINER üö´

**GLINERDD** is a tool that uses pre-trained **GLINER** models to detect entities in violent text. It also uses them to classify and verify the NER, specifically identifying the location, person, and organization.

This repository is divided into five parts:

- **Fine Tuning Training**, with the entrypoint `train_nested_kfold.py` and the training package `gliner_train/`, aims to train and generate the model after compound training.
- **Auto-Iterative Adjustments**, composed of the files "GliNER - Auto-Iterative Adjustments.py," "GliNER - Metadata Adjustments.py," and "GliNER - Sanity File Conversion.py," which aims to adjust the metadata and convert the generated algorithm to auto-iterative.
- **Pseudolabel**, composed of the files "GliNER - PseudoLabel v3.py" and "GliNER - Training - PseudoLabel - v3.py," which contain two files that generate the pseudolabel: one for the Pseudolabel training file and the other for generating the Pseudolabel file.
- **Result**, with the entrypoint `evaluate_gliner.py` and module `gliner_train/evaluate.py`, generates classification reports, calibrated thresholds, and per-class metrics.
- **Calibration**, composed of the files "GliNER - Temperature Scaling.py", "GliNER - Temperature Scaling - Classe.py", and "GliNER - Isolation Regression.py", is designed to calibrate the results generated by the pseudolabel

## Prerequisites üìã

Make sure you have the following prerequisites installed in your development environment:

- Python 3.11+
- Pip (Python package manager)
- Torch
- Scikit-learn
- matplotlib
- Gliner

## How to Run üèÉ‚Äç‚ôÄÔ∏è

Follow these simple steps to set up and run NERDD:

1. **Clone the Repository**

   ```shell
   git clone https://github.com/MLRG-CEFET-RJ/nerdd.git
   cd nerdd
   ```

2. **Install Libs on Environment**

   ```shell
   cd dd_ner_pipeline
   pip install -r requirements.txt
   ```

3. **Run Training**

   ```shell
   python3 train_nested_kfold.py
   ```

4. **Optional: override defaults**

   ```shell
   python3 train_nested_kfold.py --train-path ../data/dd_corpus_small_train.json --num-epochs 20 --n-splits 3 --n-inner-splits 3 --search-mode grid --lr-values 3.38e-5,5e-5 --weight-decay-values 0.01,0.05 --thresholds 0.5,0.6 --log-level INFO
   ```

5. **Smoke Test (local CPU / low RAM)**

   Use this command to validate that the full nested-CV pipeline finishes on a development machine before running the full training on GPU:

   ```shell
   HF_HUB_OFFLINE=1 TRANSFORMERS_OFFLINE=1 python3 train_nested_kfold.py \
     --model-base urchade/gliner_small-v2.1 \
     --train-path ../data/dd_corpus_smoke_20.json \
     --batch-size 1 \
     --max-length 32 \
     --overlap 2 \
     --num-epochs 1 \
     --n-splits 2 \
     --n-inner-splits 2 \
     --search-mode grid \
     --lr-values 3e-5 \
     --weight-decay-values 0.01 \
     --thresholds 0.6 \
     --refit-val-size 0.5 \
     --output-dir ./smoke_run_nested_tiny \
     --log-level INFO
   ```

6. **Run Evaluation (after training)**

   ```shell
   python3 evaluate_gliner.py --model-path best_overall_gliner_model --gt-jsonl gliner_teste_sanidade.json --labels Person,Location,Organization
   ```

7. **Production Training (powerful server, batch size 16)**

   Use this command on a high-memory/GPU machine:

   ```shell
   python3 train_nested_kfold.py \
     --train-path ../data/dd_corpus_small_train.json \
     --batch-size 16 \
     --num-epochs 20 \
     --n-splits 3 \
     --n-inner-splits 3 \
     --search-mode random \
     --num-trials 20 \
     --lr-values 1e-6,2e-6,5e-6,1e-5,2e-5,3e-5,5e-5,8e-5,1e-4,2e-4,3e-4 \
     --weight-decay-values 0.0,0.01,0.05 \
     --thresholds 0.5,0.6 \
     --output-dir ./run_batch16 \
     --log-level INFO
   ```

### Main Arguments

- `--train-path`: JSON/JSONL training file path (relative to `dd_ner_pipeline/` or absolute)
- `--model-base`: Base model path or model id (default: `birdred/glinerdd`)
- `--batch-size`: Batch size for training/validation dataloaders
- `--num-epochs`: Epochs per trial
- `--n-splits`: Number of outer folds
- `--n-inner-splits`: Number of inner folds (nested CV tuning)
- `--search-mode`: Hyperparameter search mode (`grid` or `random`)
- `--num-trials`: Number of random trials (used when `--search-mode random`)
- `--lr-values`: Comma-separated learning rate candidates
- `--weight-decay-values`: Comma-separated weight decay candidates
- `--thresholds`: Comma-separated list for threshold evaluation (example: `0.5,0.6`)
- `--output-dir`: Output folder for metrics, plots and best model
- `--results-file`: Human-readable nested CV report (default: `nested_cv_results.txt`)
- `--results-json-file`: Structured nested CV report (default: `nested_cv_results.json`)
- `--log-level`: `DEBUG`, `INFO`, `WARNING`, `ERROR`
- `HF_HUB_OFFLINE=1 TRANSFORMERS_OFFLINE=1`: Recommended for repeatable local smoke tests after model cache is already available

`nested_cv_results.json` now also includes:
- `seen_entity_test_f1`: F1 on test mentions whose `(label, surface)` was seen in fold training data.
- `unseen_entity_test_f1`: F1 on test mentions whose `(label, surface)` was not seen in fold training data.

## Handover Docs

- `docs/MIGRATION.md`: legacy-to-current migration notes.
- `docs/PIPELINE_OVERVIEW.md`: end-to-end pipeline summary.
- `docs/RUNBOOK.md`: ready-to-run commands (smoke/server/eval).
- `docs/ARCHITECTURE.md`: module map and responsibilities.
- `docs/EXPERIMENT_LOG_TEMPLATE.md`: template for experiment tracking.
- `CHANGELOG.md`: refactor summary.

## Contribution ü§ù

If you want to contribute to the NERDD project, we would be happy to receive your contributions. Feel free to open issues or submit pull requests with improvements, bug fixes, or new features.

## License üìÑ

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

We hope you enjoy entity recognition with **GLINERDD**! If you have any questions or need assistance, please feel free to reach out to the development team.
